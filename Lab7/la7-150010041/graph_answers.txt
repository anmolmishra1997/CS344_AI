Task 2 -
1. In general, the prediction accuracy of perceptron classifier increases with the number of iterations. This is in accordance with the expected behaviour, as the perceptron should improve with iterations. There is a slight dip at 1500 iterations though, this could be explained because the perceptron is getting monotonically better at training data, but the same cannot be claimed for validation data.

2. Both the validation and test accuracy mirror each other's behaviours. The rolling mean of accuracies in general is increasing, but there are scenarios where more training data is harming the accuracy. This could mean that with increase in training data, more scenarios could be covered but it's not necessary that we have seen enough data for the new scenarios. Eventually though, the perceptron accuracy does increase.
	
	2.1. With 1000 data points, the accuracy is around 80 percent which isn't very close to 100 percent. This is because we are training our classifier on training data while the tests are performed on different data. There would always be some gap between training accuracy and validation or test accuracy.
	2.2 It would depend on the way we initialize the weights. If the initialized weights are all 0, then the classification accuracy would be around 0 since all the scores for all categories would be identical. If the initialized weights are random, then the classification accuracy would be more positive because random classification should be predicting the correct class with probability 0.1 (in case of 10 categories assuming all the categories have roughly equal number of samples)